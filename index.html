<!DOCTYPE html>

<script src="https://d3js.org/d3.v6.min.js"></script>


<html lang="en">
   <head>
      <!-- basic -->
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <!-- mobile metas -->
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="viewport" content="initial-scale=1, maximum-scale=1">
      <!-- site metas -->
      <title>HCI-P2</title>
      <meta name="keywords" content="">
      <meta name="description" content="">
      <meta name="author" content="">
      <!-- bootstrap css -->
      <link rel="stylesheet" href="css/bootstrap.min.css">
      <!-- style css -->
      <link rel="stylesheet" href="css/style.css">
      <!-- Responsive-->
      <link rel="stylesheet" href="css/responsive.css">
      <!-- fevicon -->
      <link rel="icon" href="images/fevicon.png" type="image/gif" />
      <!-- Scrollbar Custom CSS -->
      <link rel="stylesheet" href="css/jquery.mCustomScrollbar.min.css">
      <!-- Tweaks for older IEs-->
      <link rel="stylesheet" href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css">
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.min.css" media="screen">
      <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script><![endif]-->
   </head>
   <!-- body -->
   <body class="main-layout">
      <!-- intro section -->
      <section id="intro" class="vehicles">
         <div class="container">
            <div class="row">
               <div class="col-md-12">
                  <div class="titlepage">
                     <h2>Discrimination in the US Legal Systems</h2>
                     <p>Group 7. Tiechuan Hu, Rosalyn Shin, Kyle Wu</p>
                  </div>
                  <p>Racial discrimination is widespread in the legal system of the United States.In the wake of the killing of George Floyd, discussions around police reforms have heightened and centered on how law enforcement engages with people of color.
                     The group analyzeed the data of racial bias existed in the legal systems, law enforcement engages with people of color in California, and recidivism scores. 
                     By drawing the conclusions from the data, it is clear racial disparities within the legal system continue to be a pressing issue for the nation.
                  </p>
               </div>
            </div>
         </div>
      </section>
      <!-- end intro section -->

      <!-- legal section -->
      <div id="legal" class="service">
         <div class="container">
            <div class="row">
               <div class="col-md-10 offset-md-1">
                  <div class="titlepage">
                     <h2>Current US Legal Systems</h2>
                     <p>In this section, we will discuss some statistics in the U.S. legal systems.</p>
                  </div>
               </div>
            </div>
            <div class="row">
               <div id="stop-reasons" class="col-md-6">
                  <h3>Share of reasons for stop</h3>
                  <iframe width="100%" height="600" frameborder="0" src="https://observablehq.com/embed/9afc96de5b9bdf55?cells=chart"></iframe>
               </div>

               <div id="stop-population" class="col-md-6">
                  <h3>Share of stops and population</h3>
                  <iframe width="100%" height="320" frameborder="0"src="https://observablehq.com/embed/cf0a98b40fdc53cd?cells=chart"></iframe>
               </div>
            </div>
         </div>
      </div>
      <!-- end legal section -->
      
      <!-- technology section -->
      <div id="technology" class="vehicles">
         <div class="container">
            <div class="row">
               <div class="col-md-10 offset-md-1">
                  <div class="titlepage">
                     <h2>Racial Bias and Technology<br>in the Legal Systems</h2>
                     <p>In this section, we will discuss the racial biases introduced by technologies used in the U.S. legal systems.</p>
                  </div>
               </div>
            </div>
            <div class="row">
               <div class="col-md-12">
                  <p>With the rise of machine learning, the US court also have implemented the new technology. A computer program spat out a score predicting the likelihood of each committing a future crime. Borden — who is black — was rated a high risk. Prater — who is white — was rated a low risk. Two years later, we know the computer algorithm got it exactly backward. Borden has not been charged with any new crimes. Prater is serving an eight-year prison term for subsequently breaking into a warehouse and stealing thousands of dollars’ worth of electronics.</p>
                  <p>Scores like this — known as risk assessments — are increasingly common in courtrooms across the nation. They are used to inform decisions about who can be set free at every stage of the criminal justice system, from assigning bond amounts — as is the case in Fort Lauderdale — to even more fundamental decisions about defendants’ freedom. In Arizona, Colorado, Delaware, Kentucky, Louisiana, Oklahoma, Virginia, Washington and Wisconsin, the results of such assessments are given to judges during criminal sentencing.</p>
                  <p>Rating a defendant’s risk of future crime is often done in conjunction with an evaluation of a defendant’s rehabilitation needs. The Justice Department’s National Institute of Corrections now encourages the use of such combined assessments at every stage of the criminal justice process. And a landmark sentencing reform bill currently pending in Congress would mandate the use of such assessments in federal prisons.</p>
                  <p>In 2014, then U.S. Attorney General Eric Holder warned that the risk scores might be injecting bias into the courts. He called for the U.S. Sentencing Commission to study their use. “Although these measures were crafted with the best of intentions, I am concerned that they inadvertently undermine our efforts to ensure individualized and equal justice,” he said, adding, “they may exacerbate unwarranted and unjust disparities that are already far too common in our criminal justice system and in our society.”</p>
                  <p>The sentencing commission did not, however, launch a study of risk scores. So ProPublica did, as part of a larger examination of the powerful, largely hidden effect of algorithms in American life.</p>
                  <p>We obtained the risk scores assigned to more than 7,000 people arrested in Broward County, Florida, in 2013 and 2014 and checked to see how many were charged with new crimes over the next two years, the same benchmark used by the creators of the algorithm.</p>
                  <p>The score proved remarkably unreliable in forecasting violent crime: Only 20 percent of the people predicted to commit violent crimes actually went on to do so.</p>
                  <p>When a full range of crimes were taken into account — including misdemeanors such as driving with an expired license — the algorithm was somewhat more accurate than a coin flip. Of those deemed likely to re-offend, 61 percent were arrested for any subsequent crimes within two years.</p>
               </div>  
            </div>
            <div class="row">
               <div class="col-md-12">
                  
                  <h3>Decile Scores</h3>
                  <p>ZZZ. Judges are often presented with two sets of scores from the Compas system -- one that classifies people into High, Medium and Low risk, and a corresponding decile score</p>
                  <p>Temporary plot placeholder</p>
                  <iframe width="100%" height="685" frameborder="0" src="https://observablehq.com/embed/7dbed08ef155e12c?cells=viewof+layout%2Cchart"></iframe>
                  <p>There is a clear downward trend in the decile scores as those scores increase for white defendants.</p>
               </div>             
            </div>
            <div class="row">
               <div id="pie-race" class="col-md-6">
                  <h5>Race-Level</h5>
                  <iframe width="100%" height=600 frameborder="0" src="https://observablehq.com/embed/f8a4815b8df280ac?cells=chart"></iframe>
               </div>
               <div class="col-md-6">
                  <h5>Level-Race</h5>
                  <iframe width="100%" height=600 frameborder="0" src="https://observablehq.com/embed/229711ae6f785bf9?cells=chart"></iframe>
               </div>
            </div>
            <div class="row">
               <div class="col-md-12">
                  <h3>Recidivism Scores</h3>
                  <p>nternet. It uses a dictionary of over 200 Latin words, combined with .</p>
                  <iframe width="100%" height="779.734375" frameborder="0" src="https://observablehq.com/embed/87a9da5cb68597a9?cells=viewof+N%2Cchart"></iframe>
               </div> 
            </div>
         </div>
      </div>
      <!-- end technology section -->

      <!-- conclusion section -->
      <div id="conclusion" class="testimonial bottom_cross bottom_cross2">
         <div class="container">
            <div class="row">
               <div class="col-md-12">
                  <div class="titlepage">
                     <h2>Conclusion</h2>
                  </div>
               </div>
            </div>
            <div class="row">
               <div class="col-md-12">
                  <div class="testimonial_box">
                     <h3>WIth an aim to remove human and systematic bias in our legal systems, we have adopted ML algorithms in the legal decisions. However, our analysis shows that ML has increased/incurred greater race disparity in legal decisions</h3>
                  </div>
                  <div class="testimonial_box">
                     <h3>If computers could accurately predict which defendants were likely to commit new crimes, the criminal justice system could be fairer and more selective about who is incarcerated and for how long. The trick, of course, is to make sure the computer gets it right. If it’s wrong in one direction, a dangerous criminal could go free. If it’s wrong in another direction, it could result in someone unfairly receiving a harsher sentence or waiting longer for parole than is appropriate.</h3>
                     <p>- The formula was particularly likely to falsely flag black defendants as future criminals, wrongly labeling them this way at almost twice the rate as white defendants.</p>
                     <p>- White defendants were mislabeled as low risk more often than black defendants.</p>
                  </div>
               </div>
            </div>
         </div>
      </div>
      <!-- end conclusion section -->

      <!-- reference section -->
      <section id="reference" class="vehicles">
         <div class="container">
            <div class="row">
               <div class="col-md-12">
                  <div class="titlepage">
                     <h2>References</h2>
                  </div>
                  <ul>
                     <li><a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a></li>
                     <li><a href="https://www.aclu.org/news/privacy-technology/how-is-face-recognition-surveillance-technology-racist">https://www.aclu.org/news/privacy-technology/how-is-face-recognition-surveillance-technology-racist</a></li>
                     <li></li>
                  </ul>
               </div>
            </div>
         </div>
      </section>
      <!-- end reference section -->

      

      <!--  footer -->
      <footer>
         <div class="copyright">
            <div class="container">
               <div class="row">
                  <div class="col-md-12">
                     <p>© 2019 All Rights Reserved. Design by<a href="https://html.design/"> Free Html Templates</a></p>
                  </div>
               </div>
            </div>
         </div>
      </footer>
      <!-- end footer -->
      <!-- Javascript files-->
      <script src="js/jquery.min.js"></script>
      <script src="js/popper.min.js"></script>
      <script src="js/bootstrap.bundle.min.js"></script>
      <script src="js/jquery-3.0.0.min.js"></script>
      <!-- sidebar -->
      <script src="js/jquery.mCustomScrollbar.concat.min.js"></script>
      <script src="js/custom.js"></script>
      <script>
         function openNav() {
           document.getElementById("mySidepanel").style.width = "250px";
         }
         
         function closeNav() {
           document.getElementById("mySidepanel").style.width = "0";
         }
      </script>

         

   </body>
</html>

